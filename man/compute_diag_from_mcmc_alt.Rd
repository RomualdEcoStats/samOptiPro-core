% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/diagnostics.R
\name{compute_diag_from_mcmc_alt}
\alias{compute_diag_from_mcmc_alt}
\title{Scalable diagnostics from MCMC samples (classic layout, block-wise)}
\usage{
compute_diag_from_mcmc_alt(samples, runtime_s)
}
\arguments{
\item{samples}{An \code{mcmc.list}, \code{mcmc}, or numeric matrix of MCMC
samples. All chains must share (at least) one common parameter name.}

\item{runtime_s}{Numeric scalar; total runtime in seconds for the MCMC
run(s) corresponding to \code{samples}. It is assumed to be the total wall
clock time for the full set of chains.}

\item{compute_rhat}{Character, one of \code{"none"}, \code{"classic"},
\code{"split"}, or \code{"both"} to control the computation of
Gelman–Rubin diagnostics. In the classic layout, only a single
\code{Rhat} column is returned; when both variants are requested, a
priority rule is applied internally (e.g. split-\eqn{\hat{R}} preferred
when available).}

\item{ess_for}{Character, one of \code{"both"}, \code{"worst"},
or \code{"total"}. The classic layout uses the "worst-chain" ESS for the
\code{ESS} and derived AE/CE columns; the total ESS is used internally
only when available.}

\item{ignore_patterns}{Optional character vector of regular expressions used
to remove parameters by name before computing diagnostics
(e.g. \code{"^lifted_"}, \code{"^logProb_"}).}

\item{cols_by}{Integer; number of columns per processing block. Larger values
reduce overhead but increase memory usage. Can be tuned automatically via
\code{target_block_ram_gb}.}

\item{warn_mem_gb}{Numeric; approximate memory threshold (GiB) above which a
warning is issued based on the size of the chains.}

\item{step_timeout_s}{Numeric; per-step time limit in seconds for each
diagnostic phase (ESS, total ESS, R-hat). Use \code{Inf} to disable.}

\item{runtime_is_total}{Logical; if \code{FALSE}, \code{runtime_s} is assumed
to be a per-chain runtime and is multiplied by the number of chains before
computing \code{ESS_per_sec} and \code{time_s_per_ESS}.}

\item{use_posterior}{Character; \code{"never"} or \code{"if_available"} to
optionally leverage the \pkg{posterior} package for faster and
rank-normalized ESS/\eqn{\hat{R}}. When unavailable, the function falls
back to \pkg{coda}-style computations.}

\item{target_block_ram_gb}{Numeric; if non-\code{NA}, automatically derives
\code{cols_by} to target this approximate RAM usage (GiB) per processing
block, using a conservative safety factor.}

\item{verbose}{Logical; if \code{TRUE}, print progress messages and basic
memory/blocking information.}
}
\value{
A \code{data.frame} with one row per parameter and the following columns:
\describe{
\item{target}{Parameter name (column name in the MCMC object).}
\item{ESS}{Effective sample size used for efficiency summaries
(worst-chain ESS).}
\item{AE_ESS_per_it}{Algorithmic efficiency, defined as
\code{ESS / n_iter}.}
\item{ESS_per_sec}{Computational efficiency, defined as
\code{ESS / runtime_s}.}
\item{time_s_per_ESS}{Seconds per effective sample, defined as
\code{runtime_s / ESS}.}
\item{Rhat}{Gelman–Rubin convergence diagnostic, if requested via
\code{compute_rhat}; otherwise \code{NA}.}
\item{Family}{Top-level node family (string before the first \code{"["}
in \code{target}).}
}
}
\description{
Efficiently computes convergence and efficiency diagnostics from large
\code{mcmc.list} objects using a block-wise, vectorized strategy, while
preserving the classic output layout of \code{\link{compute_diag_from_mcmc}}.
This is intended as a drop-in, scalable replacement for
\code{compute_diag_from_mcmc} in very high-dimensional hierarchical models.
}
\details{
The function is designed for models with tens of thousands of monitored
parameters (e.g. large Bayesian stock assessment or life-cycle models such as
WGNAS, GEREM, Scorff LCM), where standard \pkg{coda}-based loops become
prohibitively slow or memory bound.

Internally, all chains are first truncated to the shortest common length
and transformed into matrices with a common set of parameters. Diagnostics
(ESS and \eqn{\hat{R}}) are then computed in column blocks to control memory
use. The effective sample size used in the output,
\code{ESS}, corresponds to a conservative "worst chain" ESS (minimum across
chains), and the classic quantities are derived as:

\itemize{
\item \code{AE_ESS_per_it = ESS / n_iter},
\item \code{ESS_per_sec   = ESS / runtime_s},
\item \code{time_s_per_ESS = runtime_s / ESS}.
}

This ensures strict backward compatibility with consumers of
\code{compute_diag_from_mcmc}, while benefiting from the scalable
implementation of \code{compute_diag_from_mcmc_vect}.
}
\note{
This function is intended as a scalable, vectorized backend for
\code{compute_diag_from_mcmc}, preserving its column layout so that existing
downstream code (plots, summaries, bottleneck detectors) continues to work
without modification, even for MCMC outputs with \eqn{\ge 90{,}000}
parameters and up to \eqn{10} chains.
}
\examples{
\dontrun{
diag_alt <- compute_diag_from_mcmc_vect_alt(
  samples             = my_mcmc,
  runtime_s           = 5400,
  compute_rhat        = "both",
  ess_for             = "both",
  target_block_ram_gb = 2
)
head(diag_alt)
}

}
\seealso{
\code{\link{compute_diag_from_mcmc}},
\code{\link[coda]{effectiveSize}},
\code{\link[posterior]{ess_bulk}},
\code{\link[posterior]{rhat}},
Vehtari et al. (2021), \emph{Bayesian Analysis} 16(2):667–718.
}
