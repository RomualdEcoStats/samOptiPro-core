% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/diagnostics.R
\name{compute_diag_from_mcmc_vect}
\alias{compute_diag_from_mcmc_vect}
\title{Compute Diagnostics from MCMC Samples (massively scalable)}
\usage{
compute_diag_from_mcmc_vect(
  samples,
  runtime_s,
  compute_rhat = c("none", "classic", "split", "both"),
  ess_for = c("both", "worst", "total"),
  ignore_patterns = c("^lifted_", "^logProb_"),
  cols_by = 5000L,
  warn_mem_gb = 10,
  step_timeout_s = Inf,
  runtime_is_total = TRUE,
  use_posterior = c("never", "if_available"),
  target_block_ram_gb = NA_real_,
  verbose = TRUE
)
}
\arguments{
\item{samples}{A \code{mcmc.list}, \code{mcmc}, or numeric matrix of MCMC samples.}

\item{runtime_s}{Numeric scalar; runtime in seconds (total or per-chain).}

\item{compute_rhat}{Character, one of \code{"none"}, \code{"classic"},
\code{"split"}, or \code{"both"} (default: \code{"none"}).}

\item{ess_for}{Character, one of \code{"both"}, \code{"worst"}, or \code{"total"}.}

\item{ignore_patterns}{Character vector of regex patterns to remove from
parameter names (e.g. \code{"^lifted_"}, \code{"^logProb_"}).}

\item{cols_by}{Integer; number of columns per processing block (≥1000).
Can be set to \code{"auto"} via \code{target_block_ram_gb}.}

\item{warn_mem_gb}{Numeric; memory threshold above which a warning is issued.}

\item{step_timeout_s}{Numeric; per-block time limit in seconds.}

\item{runtime_is_total}{Logical; if \code{FALSE}, \code{runtime_s} is per-chain
and multiplied by \eqn{m}.}

\item{use_posterior}{Character; \code{"never"} or \code{"if_available"} to use
the \pkg{posterior} package for ESS/R-hat.}

\item{target_block_ram_gb}{Numeric; if non-NA, auto-computes \code{cols_by}
to target this RAM usage per block.}

\item{verbose}{Logical; display progress messages.}
}
\value{
A \code{data.frame} with one row per parameter and the following columns:
\describe{
\item{target}{Parameter name.}
\item{ESS_worst}{Minimum ESS across chains.}
\item{ESS_total}{Combined ESS across all chains.}
\item{AE_worst, AE_total}{Algorithmic efficiencies.}
\item{ESS_per_sec_worst, ESS_per_sec_total}{Computational efficiencies.}
\item{time_s_per_ESS_worst, time_s_per_ESS_total}{Seconds per effective sample.}
\item{Rhat_classic, Rhat_split}{Gelman-Rubin diagnostics (classic/split).}
\item{Family}{Top-level node family (extracted from target name).}
}
}
\description{
Efficiently computes convergence and efficiency diagnostics (ESS, R-hat,
algorithmic efficiency, and computational efficiency) from a large
\code{mcmc.list} object — designed for very high-dimensional hierarchical models
(>90 000 parameters). The function operates in column blocks to control memory
usage, and optionally leverages the \pkg{posterior} package for faster and
rank-normalized diagnostics.
}
\details{
This implementation (\strong{RevA_2025-10-31}) is optimized for large Bayesian
Stock-Assessment or life-cycle models (e.g. WGNAS, GEREM, Scorff LCM) where
standard \pkg{coda} routines become memory-bound.  It avoids unnecessary
matrix copies, pre-truncates to the shortest chain length, and computes
diagnostics by column blocks to maintain stability under limited RAM.

\strong{Formulas:}
\deqn{ESS_{worst} = \min_c ESS_c(\theta_i)}{}
\deqn{ESS_{total} = ESS(\text{pooled chains})}{}
\deqn{\hat{R} = \sqrt{\hat{Var}^+ / W}, \qquad \hat{Var}^+ = \frac{n-1}{n}W + \frac{B}{n}}{}
Algorithmic efficiency: \eqn{AE = ESS / n_{iter}}.
Computational efficiency: \eqn{CE = ESS / t_{run}}.
}
\note{
\strong{Stability:} validated for ≥ 90 000 parameters and ≤ 10 chains.
}
\examples{
\dontrun{
res_diag <- compute_diag_from_mcmc(samples = my_mcmc,
                                   runtime_s = 5400,
                                   compute_rhat = "both",
                                   ess_for = "both",
                                   target_block_ram_gb = 2)
head(res_diag)
}

}
\seealso{
\code{\link[coda]{effectiveSize}}, \code{\link[posterior]{ess_bulk}},
\code{\link[posterior]{rhat}}, Vehtari et al. (2021) \emph{Bayesian Analysis 16(2):667–718},
Gelman & Rubin (1992), Brooks & Gelman (1998).
}
