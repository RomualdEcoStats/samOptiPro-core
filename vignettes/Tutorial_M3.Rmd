---
title: "Exploring Differentiability and Sampler Optimization in NIMBLE: A Step-by-Step
  Tutorial with *samOptiPro*"
author: "Romuald H"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  beamer_presentation: default
  bookdown::pdf_document2:
    fig_caption: true
    toc: false
    latex_engine: xelatex
  bookdown::word_document2:
    fig_caption: true
    number_sections: true
    toc: false
  bookdown::html_document2:
    fig_caption: true
    number_sections: true
    toc: false
  powerpoint_presentation:
    slide_level: 1
    reference_doc: template_conf.potx
    keep_md: false
  slidy_presentation: default
linestretch: 1.5
site: bookdown::bookdown_site
language: "en-EN"
editor_options:
  markdown:
    wrap: sentence
---
```{r load-samoptipro, include=FALSE}

path_pkg <- "~/Scorff LCM_model1/samOptiPro"

if (!requireNamespace("samOptiPro", quietly = TRUE)) {
  if (requireNamespace("devtools", quietly = TRUE) && dir.exists(path_pkg)) {
    message("Loading samOptiPro from source: ", path_pkg)
    devtools::load_all(path_pkg, quiet = TRUE)
  } else {
    stop("samOptiPro not found. Either install it or set 'path_pkg' correctly.")
  }
}
library(samOptiPro)

```

```{r setup, include=FALSE}
library(knitr)

knitr::opts_chunk$set(dev = "ragg_png",comment=NA, echo = FALSE,  cache=TRUE, message=FALSE,warning=FALSE, error=FALSE,fig.width=8,fig.height=4,bg="transparent", cache.lazy=FALSE)
set.seed(123)
ilogit <- plogis; logit <- qlogis
`%||%` <- function(x, y) if (is.null(x)) y else x

```
#Introduction

This tutorial demonstrates how to **diagnose differentiability** and **optimize MCMC sampling strategies** in complex Bayesian state–space models using the R package **`samOptiPro`** (Hounyeme *et al.*, 2025).  
We illustrate the workflow on a simple population dynamics model, using `nimble` and `nimbleHMC` as the computational back-end.

We will:
- Build and simulate a **population growth model** with latent process and log-normal observations.
- Identify bottelenecks (Algorithmic bottelenecks or and Time bottelelnecks)
- Diagnose **non-differentiable components** (to decide whether HMC/NUTS is applicable).
- Automatically **benchmark samplers** (RW, Slice, AF_slice, HMC, NUTS) using `test_strategy_block()`.
- Assess **algorithmic (AE)** and **computational efficiency (CE)**.

All results (traceplots, diagnostics, and performance summaries) are saved under `outputs/`.


# Step 0- Load packages
```{r Load Packages}
library(coda)
library(ggplot2)
library(nimble)
library(nimbleHMC)
#Load samOptiPro

#library(samOptiPro)
```

#Step 1. Simulated Data, Initial Values and monitors

```{r Inputs Data & Monitors, echo=FALSE}
# Simulation constants
time <- 8
Const_nimble <- list(
  n        = time,
  sd_dummy = 0.05,
  sd_obs   = c(0.05, rep(0.4, time - 1))
)

# Data simulation
set.seed(42)
Nobs  <- numeric(time)
theta <- numeric(time - 1)
Nobs[1] <- rlnorm(1, meanlog = 10, sdlog = 0.5)
for(t in 1:(time - 1)){
  theta[t]  <- runif(1, 0.7, 0.9)
  Nobs[t+1] <- Nobs[t] * theta[t]
}
Data_nimble <- list(Nobs = Nobs)

# Initial values
Inits_nimble <- list(
  N           = 2e4 * c(1, cumprod(rep(0.8, time - 1))),
  logit_theta = rep(logit(0.8), time - 1)
)

# Load Monitors -----------------------------------------------------------
monitors = c("N", "theta", "logit_theta")

```

#Step 2. Model M3

```{r Model nimble}
M3.nimble <- nimbleCode({
  # priors
  for(t in 1:(n-1)){
    logit_theta[t] ~ dnorm(mean = 2, sd = 1)
    theta[t] <- ilogit(logit_theta[t])
  }
  N[1] ~ dlnorm(meanlog = 10, sdlog = 5)

  # process model
  for(t in 1:(n-1)){
    N[t+1] <- N[t] * theta[t]
  }

  # observation model
  Nobs[1] ~ dlnorm(meanlog = log(N[1]), sdlog = sd_obs[1])
  for(t in 3:n){
    Nobs[t] ~ dlnorm(meanlog = log(N[t]), sdlog = sd_obs[t])
  }
})

print(M3.nimble)
```

# Step 3. Building and Compiling the Model

```{r Building & Compiling}
nimbleOptions(buildInterfacesForCompiledNestedNimbleFunctions = TRUE)
nimbleOptions(MCMCsaveHistory = FALSE)

m  <- nimbleModel(code = M3.nimble, name = "M3",
                  constants = Const_nimble,
                  data = Data_nimble,
                  inits = Inits_nimble,buildDerivs=TRUE)
cm <- compileNimble(m)
## build_M is a central object in the samOptiPro package, as it will feed most of the subsequent functions.
build_M <- function() list(
  model    = m,
  cmodel   = cm,
  monitors = monitors,
  code_text = paste(deparse(M3.nimble), collapse = "\n")
)

```

# Step 4 . Diagnosing Differentiability and HMC Eligibility

```{r Diagnosing Differentiability and HMC Eligibility,message=FALSE, warning=FALSE}

cat("\n[MODEL STRUCTURE CHECK]\n")
diag_s <- diagnose_model_structure(m)
cat(sprintf("- Stochastic nodes   : %d\n", length(diag_s$stochastic_nodes)))
cat(sprintf("- Deterministic nodes: %d\n", length(diag_s$deterministic_nodes)))
out <- run_structure_and_hmc_test(build_M, include_data = FALSE)

```

# Step 5. Baseline MCMC, Bottelenecks and Performance Assessment


```{r  Baseline MCMC and Performance Assessment,message=FALSE, warning=FALSE}
n.iter   <- 1e6
n.burnin <- 1e4
n.thin   <- 2
n.chains <- 3

res_b <- run_baseline_config(
  build_M,
  niter   = n.iter,
  nburnin = n.burnin,
  nchains = n.chains,
  thin    = n.thin,
  monitors = monitors
)

samples_ml <- as_mcmc_list_sop(res_b$samples, res_b$samples2,
                               drop_loglik = FALSE, thin = n.thin)

runtime_s <- res_b$runtime_s   # Time total
ap  <- assess_performance(samples_ml, runtime_s)

bot <- identify_bottlenecks_family(samples_ml,
                            runtime_s,
                            ess_threshold = 1000,
                            time_threshold = "auto",
                            rhat_threshold = 1.01,
                            ess_per_s_min = 0)
runtime_s
ap$summary
bot$top3
#bot$details$algo   # worst bot in AE (low AE)
#bot$details$comp   # worst bot in CE (high cost)
#bot$details$joint  # worst bot "simultaneously" 
```

# Step 6-Adaptive Block Strategy — test_strategy_block()

```{r Adaptive Block Strategy — test_strategy_block(),message=FALSE, warning=FALSE}
#diff <- test_strategy(
  #build_M,
  #monitors = monitors,
  #try_hmc  = FALSE,
  #nchains  = 3,
  #pilot_niter  = 4000,
  #pilot_burnin = 1000,
  #thin     = 2,
 # out_dir  = "outputs/diagnostics_preliminary"
#)

#diff$messages
#diff$plan
#diff$baseline$performance$summary
#diff$strategy$performance$summary

diffB <- test_strategy_block(
    build_M,
    monitors = monitors,
    try_hmc  = TRUE,
    nchains  = 3,
    pilot_niter  = 1e6,
    pilot_burnin = 1e4,
    thin     = 2,
    out_dir  = "outputs/diagnostics_preliminary",family_mode = "auto",
    corr_threshold = 0.3,
    rwblock_control = list(adaptScaleOnly = TRUE)
)
#try_hmc= TRUE by default, to allow the algorithm to run the model under HMC/NUTS, and False if the model is not differentiable.
#family_mode = "auto" lets the algorithm decide between:
#block sampling (using NUTS / AF_slice / RW_block when correlations are high), or slice_each (independent samplers otherwise).

diffB$messages
diffB$plan$mode_global
diffB$baseline$performance$summary
diffB$strategy$performance$summary

```

# Step-7. Visualization and Diagnostics
```{r  Visualization and Diagnostics,message=FALSE, warning=FALSE,fig.cap="", out.width="90%",echo=TRUE, results='asis'}

diag_tbl <- compute_diag_from_mcmc(samples_ml, runtime_s = res_b$runtime_s)

plots_cv<-plot_convergence_checks(samples_ml,
  out_dir = "outputs/diagnostics",
  make_rhat_hist   = TRUE,
  make_rhat_ecdf   = TRUE,
  make_traces_rhat = FALSE,
  make_traces_ae   = FALSE
)

print(plots_cv$rhat_ecdf)
print(plots_cv$rhat_hist)

plots_bn <- plot_bottlenecks(
  diag_tbl,
  out_dir = "outputs/diagnostics",
  make_time_targets   = FALSE,
  make_esss_targets   = FALSE,
  make_esss_families  = TRUE,
  make_time_families  = TRUE,
  make_joint_targets  = FALSE,
  make_joint_families = FALSE,
  make_rhat_hist_targets    = FALSE,
  make_rhat_ecdf_targets    = TRUE,
  make_rhat_worst_targets   = FALSE,
  make_rhat_median_families = TRUE
)

print(plots_bn$rhat_ecdf_targets)
print(plots_bn$rhat_median_families)
print(plots_bn$time_families)
print(plots_bn$esss_families)

#The Empirical Cumulative Distribution Function (ECDF) displays the cumulative proportion of nodes whose Rhat is below a certain threshold.
#plot_bottlenecks() visualizes the worst nodes in terms of ESS/s (Algorithmic Efficiency) and runtime (Computational Efficiency).
#plot_convergence_checks() produces traceplots, autocorrelation, and R-hat diagnostics for the top problematic parameters
```

#9. Conclusions

This workflow highlights how samOptiPro helps:

Detect non-differentiable nodes that prevent HMC/NUTS usage.

Automatically switch between gradient-based and non-gradient samplers.

Quantify algorithmic and computational efficiency for each parameter family.

Provide transparent diagnostic plots and benchmark reports.

Even for a simple state–space model, the adaptive block design ensures faster convergence and improved mixing without manual tuning.

#10. References
