% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/diagnostics.R
\name{compute_diag_from_mcmc_vect}
\alias{compute_diag_from_mcmc_vect}
\title{Scalable diagnostics from MCMC samples (block-wise)}
\usage{
compute_diag_from_mcmc_vect(
  samples,
  runtime_s,
  compute_rhat = c("none", "classic", "split", "both"),
  ess_for = c("both", "worst", "total"),
  ignore_patterns = c("^lifted_", "^logProb_"),
  cols_by = 5000L,
  warn_mem_gb = 10,
  step_timeout_s = Inf,
  runtime_is_total = TRUE,
  use_posterior = c("never", "if_available"),
  target_block_ram_gb = NA_real_,
  verbose = TRUE
)
}
\arguments{
\item{samples}{An \code{mcmc.list}, \code{mcmc}, or numeric matrix of MCMC samples.}

\item{runtime_s}{Numeric scalar; runtime in seconds (total or per chain).}

\item{compute_rhat}{Character, one of \code{"none"}, \code{"classic"},
\code{"split"}, or \code{"both"} (default \code{"none"}).}

\item{ess_for}{Character, one of \code{"both"}, \code{"worst"}, or \code{"total"}.}

\item{ignore_patterns}{Character vector of regular expressions used to drop
parameters by name (for example \code{"^lifted_"}, \code{"^logProb_"}).}

\item{cols_by}{Integer; number of columns per processing block
(typically \eqn{\ge 1000}). Can be tuned automatically via
\code{target_block_ram_gb}.}

\item{warn_mem_gb}{Numeric; memory threshold (GiB) above which a warning
is issued.}

\item{step_timeout_s}{Numeric; per-block time limit in seconds.}

\item{runtime_is_total}{Logical; if \code{FALSE}, \code{runtime_s} is assumed
to be per chain and is multiplied by the number of chains.}

\item{use_posterior}{Character; \code{"never"} or \code{"if_available"} to use
the \pkg{posterior} package for ESS and R-hat.}

\item{target_block_ram_gb}{Numeric; if non-NA, automatically computes
\code{cols_by} to target this RAM usage (GiB) per block.}

\item{verbose}{Logical; if \code{TRUE}, display progress messages.}
}
\value{
A \code{data.frame} with one row per parameter and the following columns:
\describe{
\item{target}{Parameter name.}
\item{ESS_worst}{Minimum ESS across chains.}
\item{ESS_total}{Combined ESS across all chains.}
\item{AE_worst, AE_total}{Algorithmic efficiencies.}
\item{ESS_per_sec_worst, ESS_per_sec_total}{Computational efficiencies.}
\item{time_s_per_ESS_worst, time_s_per_ESS_total}{Seconds per effective sample.}
\item{Rhat_classic, Rhat_split}{Gelman-Rubin diagnostics (classic / split).}
\item{Family}{Top-level node family (extracted from \code{target}).}
}
}
\description{
Efficiently computes convergence and efficiency diagnostics (ESS, R-hat,
algorithmic efficiency, and computational efficiency) from large
\code{mcmc.list} objects, designed for very high-dimensional hierarchical models
(for example, more than 90,000 parameters). The function operates in column
blocks to control memory usage and can optionally leverage the \pkg{posterior}
package for faster and rank-normalized diagnostics.
}
\details{
This implementation is optimized for large Bayesian stock assessment or
life-cycle models (for example, WGNAS, GEREM, Scorff LCM) where standard
\pkg{coda} routines become memory bound. It avoids unnecessary matrix copies,
truncates all chains to the shortest length, and computes diagnostics in
column blocks to maintain stability under limited RAM.

\strong{Formulas:}
\deqn{ESS_{worst} = \min_c ESS_c(\theta_i)}{}
\deqn{ESS_{total} = ESS(\text{pooled chains})}{}
Algorithmic efficiency: \eqn{AE = ESS / n_{iter}}.\\
Computational efficiency: \eqn{CE = ESS / t_{run}}.
}
\note{
Stability empirically validated for models with at least
\eqn{90,000} parameters and at most \eqn{10} chains.
}
\examples{
\dontrun{
res_diag <- compute_diag_from_mcmc_vect(
  samples   = my_mcmc,
  runtime_s = 5400,
  compute_rhat         = "both",
  ess_for              = "both",
  target_block_ram_gb  = 2
)
head(res_diag)
}

}
\seealso{
\code{\link[coda]{effectiveSize}}, \code{\link[posterior]{ess_bulk}},
\code{\link[posterior]{rhat}}, Vehtari et al. (2021),
\emph{Bayesian Analysis} 16(2):667--718.
}
